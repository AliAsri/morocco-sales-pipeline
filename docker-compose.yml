# docker-compose.yml

version: '3'
x-airflow-common:
  &airflow-common
  # Use the official Airflow image
  image: apache/airflow:2.9.2
  environment:
    # Define Airflow configurations
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
  volumes:
    # Mount local folders into the container for development
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./data:/opt/airflow/data
  depends_on:
    - postgres

services:
  postgres:
    # Use the official PostgreSQL image for the metadata database
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      # Expose the Airflow UI on port 8080
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname \"$$HOSTNAME\""]
      interval: 30s
      timeout: 10s
      retries: 3

  airflow-init:
    # This service initializes the Airflow database
    <<: *airflow-common
    command: >
      bash -c "
        airflow db init &&
        airflow users create --role Admin --username airflow --password airflow --email admin@example.com --firstname admin --lastname admin
      "